{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "IoR_JsYX6iCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ae23a212-055b-411e-98e6-f4a1b2407dbf"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "JO53fGdz6nNZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 뉴스 기사 분류: 다중 분류 문제\n",
        "\n",
        "두 개 이상의 클래스가 있을 때는 어떻게 해야 할까?\n",
        "\n",
        "로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망 만들기. 클래스가 많기 때문에 이 문제는 다중 분류다. 각 데이터 포인트가 정확히 하나의 범주로 분류되기 때문에 좀 더 정확히 말하면 단일 레이블 다중 분류 문제이다. 각 데이터 포인트가 여러 개의 범주(가령, 토픽)에 속할 수 있다면 이런 문제는 다중 레이블 다중 분류의 문제가 된다.\n",
        "\n",
        "\n",
        "# 로이터 데이터셋 \n",
        "1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합인 로이터 데이터셋을 사용. 이 데이터셋은 텍스트 분류를 위해 널리 사용되는 간단한 데이터셋이다. 46개의 토픽이 있으며 어떤 토픽은 다른 것에 비해 데이터가 많다. 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있습니다.\n"
      ]
    },
    {
      "metadata": {
        "id": "eSavMUqY7Uh9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7a43209c-a91a-47dd-83b7-631352214d41"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VSpHEitD7Vjl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "매개변수는 데이터에서 가장 자주 등장하는 단어 10,000개로 제한.\n",
        "\n",
        "train : 8,982개 test : 2,246개"
      ]
    },
    {
      "metadata": {
        "id": "s-nmxErI7eLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "01e8800d-5cec-4fd1-a055-2eae21b9cdde"
      },
      "cell_type": "code",
      "source": [
        "len(train_data)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8982"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "HZkafa_M7lbk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de27c7e2-f919-4752-cd12-fb40bf232755"
      },
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "mSCJ_ulO7kag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "0f3d6a18-7da0-4c71-d4c3-13c2aaf67409"
      },
      "cell_type": "code",
      "source": [
        "train_data[10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 245,\n",
              " 273,\n",
              " 207,\n",
              " 156,\n",
              " 53,\n",
              " 74,\n",
              " 160,\n",
              " 26,\n",
              " 14,\n",
              " 46,\n",
              " 296,\n",
              " 26,\n",
              " 39,\n",
              " 74,\n",
              " 2979,\n",
              " 3554,\n",
              " 14,\n",
              " 46,\n",
              " 4689,\n",
              " 4329,\n",
              " 86,\n",
              " 61,\n",
              " 3499,\n",
              " 4795,\n",
              " 14,\n",
              " 61,\n",
              " 451,\n",
              " 4329,\n",
              " 17,\n",
              " 12]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "EFCNyECS7ruo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9e803fe9-7a54-40a0-9688-5ba4bdbd1426"
      },
      "cell_type": "code",
      "source": [
        "#단어 디코딩 법\n",
        "\n",
        "\n",
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
        "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YjnjrtDq7yoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "dc5922b0-872d-4a73-cee4-241154485a1d"
      },
      "cell_type": "code",
      "source": [
        "decoded_newswire"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "ek15iWqx70me",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "샘플에 연결된 레이블은 토픽의 인덱스로 0과 45 사이의 정수"
      ]
    },
    {
      "metadata": {
        "id": "N_gz1RR773O9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d1c01c2-260c-4bef-d8d7-f99f2ba9e87b"
      },
      "cell_type": "code",
      "source": [
        "train_labels[10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "mbUK05MJ76y-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 데이터 준비\n",
        "데이터를 벡터로 변환하기"
      ]
    },
    {
      "metadata": {
        "id": "4vEJn3sV8AQl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "# 훈련 데이터 벡터 변환\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# 테스트 데이터 벡터 변환\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fY8pvdh88DMp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "레이블을 벡터로 바꾸는 방법은 2가지가 있다.\n",
        "\n",
        ">방법1 : 레이블의 리스트를 정수 텐서로 변환하는 것\n",
        "\n",
        ">방법2 :  원-핫 인코딩을 사용하는 것. 원-핫 인코딩이 범주형 데이터에 널리 사용되기 때문에 범주형 인코딩이라고도 부른다. 이 경우 레이블의 원-핫 인코딩은 각 레이블의 인덱스 자리는 1이고 나머지는 모두 0인 벡터다"
      ]
    },
    {
      "metadata": {
        "id": "G25yLcui8DW5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_one_hot(labels, dimension=46):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "    return results\n",
        "\n",
        "# 훈련 레이블 벡터 변환\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "# 테스트 레이블 벡터 변환\n",
        "one_hot_test_labels = to_one_hot(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DwuxzEuT8D7t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wGat0-sg8K0F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 모델 구성\n",
        "이 토픽 분류 문제는 이전의 영화 리뷰 분류 문제와 비슷해 보이나 여기에서는 출력 클래스의 개수가 2에서 46개로 늘어난 점입니다. 출력 공간의 차원이 훨씬 커졌다.\n",
        "\n",
        "이전에 사용했던 것처럼 Dense 층을 쌓으면 각 층은 이전 층의 출력에서 제공한 정보만 사용할 수 있다. 한 층이 분류 문제에 필요한 일부 정보를 누락하면 그 다음 층에서 이를 복원할 방법이 없다. 각 층은 잠재적으로 정보의 병목이 될 수 있다. 이전 예제에서 16차원을 가진 중간층을 사용했지만 *16차원 공간은 46개의 클래스를 구분하기에 너무 제약이 많을 것 같다. 이렇게 규모가 작은 층은 유용한 정보를 완전히 잃게 되는 정보의 병목 지점처럼 동작할 수 있다.*\n",
        "\n",
        "이런 이유로 좀 더 규모가 큰 층을 사용하자. 64개의 유닛을 사용:"
      ]
    },
    {
      "metadata": {
        "id": "l2QmIu6r9Ndp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "18ca7b64-e035-4352-cbe8-9ed51915b1d5"
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "koLoScHL9Nuo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 구조에서 주목할 점:\n",
        "\n",
        "마지막 Dense 층의 크기가 46이다. 각 입력 샘플에 대해서 46차원의 벡터를 출력한다는 뜻. 이 벡터의 각 원소(각 차원)은 각기 다른 출력 클래스가 인코딩된 것이고 마지막 층에 softmax 활성화 함수가 사용되었다. (MNIST 예제에서 이런 방식을 봤다. )각 입력 샘플마다 46개의 출력 클래스에 대한 확률 분포를 출력한다. 즉, 46차원의 출력 벡터를 만들며 output[i]는 어떤 샘플이 클래스 i에 속할 확률이다. 46개의 값을 모두 더하면 1이 된다.\n",
        "이런 문제에 사용할 **최선의 손실 함수는 categorical_crossentropy**이다. 이 함수는 두 확률 분포의 사이의 거리를 측정한다. 여기에서는 네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리이다*. 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련하게 된다.*"
      ]
    },
    {
      "metadata": {
        "id": "chHQktJQ-BvZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GbEjgVYd9Ojt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 훈련 검증\n",
        "훈련 데이터에서 1,000개의 샘플을 따로 떼어서 검증 세트로 사용"
      ]
    },
    {
      "metadata": {
        "id": "KBCMm1iG-X0F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LR4rr20T-XLR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "20번의 에포크로 모델 훈련하기"
      ]
    },
    {
      "metadata": {
        "id": "O3QbOofq-del",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "outputId": "5c8962cb-a993-4297-9d85-90452a9472c8"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "7982/7982 [==============================] - 1s 184us/step - loss: 2.5322 - acc: 0.4955 - val_loss: 1.7208 - val_acc: 0.6120\n",
            "Epoch 2/20\n",
            "7982/7982 [==============================] - 1s 154us/step - loss: 1.4452 - acc: 0.6879 - val_loss: 1.3459 - val_acc: 0.7060\n",
            "Epoch 3/20\n",
            "7982/7982 [==============================] - 1s 151us/step - loss: 1.0953 - acc: 0.7651 - val_loss: 1.1708 - val_acc: 0.7430\n",
            "Epoch 4/20\n",
            "7982/7982 [==============================] - 1s 150us/step - loss: 0.8697 - acc: 0.8165 - val_loss: 1.0793 - val_acc: 0.7590\n",
            "Epoch 5/20\n",
            "7982/7982 [==============================] - 1s 152us/step - loss: 0.7033 - acc: 0.8470 - val_loss: 0.9843 - val_acc: 0.7820\n",
            "Epoch 6/20\n",
            "7982/7982 [==============================] - 1s 152us/step - loss: 0.5665 - acc: 0.8797 - val_loss: 0.9412 - val_acc: 0.8040\n",
            "Epoch 7/20\n",
            "7982/7982 [==============================] - 1s 151us/step - loss: 0.4579 - acc: 0.9047 - val_loss: 0.9081 - val_acc: 0.8010\n",
            "Epoch 8/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.3695 - acc: 0.9230 - val_loss: 0.9367 - val_acc: 0.7900\n",
            "Epoch 9/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.3031 - acc: 0.9313 - val_loss: 0.8925 - val_acc: 0.8090\n",
            "Epoch 10/20\n",
            "7982/7982 [==============================] - 1s 150us/step - loss: 0.2538 - acc: 0.9416 - val_loss: 0.9058 - val_acc: 0.8110\n",
            "Epoch 11/20\n",
            "7982/7982 [==============================] - 1s 151us/step - loss: 0.2186 - acc: 0.9464 - val_loss: 0.9180 - val_acc: 0.8140\n",
            "Epoch 12/20\n",
            "7982/7982 [==============================] - 1s 152us/step - loss: 0.1871 - acc: 0.9509 - val_loss: 0.9048 - val_acc: 0.8140\n",
            "Epoch 13/20\n",
            "7982/7982 [==============================] - 1s 152us/step - loss: 0.1699 - acc: 0.9524 - val_loss: 0.9327 - val_acc: 0.8100\n",
            "Epoch 14/20\n",
            "7982/7982 [==============================] - 1s 151us/step - loss: 0.1534 - acc: 0.9553 - val_loss: 0.9683 - val_acc: 0.8070\n",
            "Epoch 15/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.1390 - acc: 0.9559 - val_loss: 0.9682 - val_acc: 0.8150\n",
            "Epoch 16/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.1314 - acc: 0.9565 - val_loss: 1.0202 - val_acc: 0.8050\n",
            "Epoch 17/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.1219 - acc: 0.9580 - val_loss: 1.0247 - val_acc: 0.7980\n",
            "Epoch 18/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.1195 - acc: 0.9579 - val_loss: 1.0431 - val_acc: 0.8050\n",
            "Epoch 19/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.1136 - acc: 0.9594 - val_loss: 1.0966 - val_acc: 0.7970\n",
            "Epoch 20/20\n",
            "7982/7982 [==============================] - 1s 152us/step - loss: 0.1112 - acc: 0.9592 - val_loss: 1.0685 - val_acc: 0.8020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ypLPre_H-gqx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ltYhV8cY-g5p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f4bc55d4-796c-44de-8ce9-b43ac2668762"
      },
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "W4bpRDrx-mBx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a90d5875-449d-4183-f93d-05a388888e32"
      },
      "cell_type": "code",
      "source": [
        "plt.clf()   # 그래프를 초기화합니다\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gJe2tw6--oEe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 모델은 9번째 에포크 이후에 과대적합이 시작됨. 9번의 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가하자"
      ]
    },
    {
      "metadata": {
        "id": "QMMtSTnD-wMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "f8b89952-7860-4b11-f137-2c978df711c1"
      },
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=9,\n",
        "          batch_size=512,\n",
        "          validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, one_hot_test_labels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/9\n",
            "7982/7982 [==============================] - 2s 193us/step - loss: 2.5398 - acc: 0.5226 - val_loss: 1.6733 - val_acc: 0.6570\n",
            "Epoch 2/9\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 1.3712 - acc: 0.7121 - val_loss: 1.2758 - val_acc: 0.7210\n",
            "Epoch 3/9\n",
            "7982/7982 [==============================] - 1s 154us/step - loss: 1.0136 - acc: 0.7781 - val_loss: 1.1303 - val_acc: 0.7530\n",
            "Epoch 4/9\n",
            "7982/7982 [==============================] - 1s 154us/step - loss: 0.7976 - acc: 0.8251 - val_loss: 1.0539 - val_acc: 0.7590\n",
            "Epoch 5/9\n",
            "7982/7982 [==============================] - 1s 154us/step - loss: 0.6393 - acc: 0.8624 - val_loss: 0.9754 - val_acc: 0.7920\n",
            "Epoch 6/9\n",
            "7982/7982 [==============================] - 1s 155us/step - loss: 0.5124 - acc: 0.8923 - val_loss: 0.9102 - val_acc: 0.8140\n",
            "Epoch 7/9\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.4123 - acc: 0.9137 - val_loss: 0.8932 - val_acc: 0.8210\n",
            "Epoch 8/9\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.3354 - acc: 0.9288 - val_loss: 0.8732 - val_acc: 0.8260\n",
            "Epoch 9/9\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.2782 - acc: 0.9371 - val_loss: 0.9337 - val_acc: 0.8010\n",
            "2246/2246 [==============================] - 0s 94us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U1R_6-mx-ybW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee6f0cb9-110e-49f2-ae8a-b38f8a637eeb"
      },
      "cell_type": "code",
      "source": [
        "results"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.022207990036622, 0.7756010686194165]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "7pCeAR37-1QY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "대략 78%의 정확도를 보인다. 균형 잡힌 이진 분류 문제에서 완전히 무작위로 분류하면 50%의 정확도를 달성한다. 이 문제는 불균형한 데이터셋을 사용하므로 무작위로 분류하면 19% 정도를 달성한다. 여기에 비하면  꽤 좋은 결과이다."
      ]
    },
    {
      "metadata": {
        "id": "Q02DjfNB-0Qq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "412dfcc7-99a8-4852-c1e8-759ab6d938f8"
      },
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "test_labels_copy = copy.copy(test_labels)\n",
        "np.random.shuffle(test_labels_copy)\n",
        "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.182546749777382"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "qYgXellN_IhW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 새로운 데이터에 대해 예측하기\n",
        "모델 인스턴스의 predict 메서드는 46개 토픽에 대한 확률 분포를 반환한다. 테스트 데이터 전체에 대한 토픽을 예측하자"
      ]
    },
    {
      "metadata": {
        "id": "Ul1ws9Uq_Ite",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t9rnqCe9_I6q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "predictions의 각 항목은 길이가 46인 벡터"
      ]
    },
    {
      "metadata": {
        "id": "WYqRZ4de_JDa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5626098a-846b-444f-cf44-898060bec37b"
      },
      "cell_type": "code",
      "source": [
        "predictions[0].shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "2vVuVPcl_JM6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "벡터의 원소 합은 1이다."
      ]
    },
    {
      "metadata": {
        "id": "zs_HwOSF_auR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9d4c99b1-af60-497c-ad06-1ee2c65ba8f5"
      },
      "cell_type": "code",
      "source": [
        "np.sum(predictions[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "hx0FJ-iQ_cnN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 레이블과 손실을 다루는 다른 방법\n",
        "앞서 언급한 것처럼 레이블을 인코딩하는 다른 방법은 다음과 같이 정수 텐서로 변환하는 것이다:"
      ]
    },
    {
      "metadata": {
        "id": "cAcCfeL4_gKl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QzJh0LoW_jcF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 방식을 사용하려면 손실 함수 하나만 바꾸면 돤다.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "HUPchb-Z_iXB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HpeNNghK_mSW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 손실 함수는 인터페이스만 다를 뿐이고 수학적으로는 categorical_crossentropy와 동일함."
      ]
    },
    {
      "metadata": {
        "id": "2gGIdiTA_mWF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "충분히 큰 중간층을 두어야 하는 이유\n",
        "앞서 언급한 것처럼 마지막 출력이 46차원이기 때문에 중간층의 히든 유닛이 46개보다 많이 적어서는 안 된다. 46차원보다 훨씬 작은 중간층(예를 들면 4차원)을 두면 정보의 병목이 어떻게 나타나는지 확인해야 한다."
      ]
    },
    {
      "metadata": {
        "id": "FiKVtERk_mnh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "18112935-5afc-4dff-a9a5-36fde080d17c"
      },
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(4, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "7982/7982 [==============================] - 3s 333us/step - loss: 2.6581 - acc: 0.3776 - val_loss: 1.9677 - val_acc: 0.5350\n",
            "Epoch 2/20\n",
            "7982/7982 [==============================] - 2s 258us/step - loss: 1.6663 - acc: 0.6218 - val_loss: 1.5409 - val_acc: 0.6230\n",
            "Epoch 3/20\n",
            "7982/7982 [==============================] - 2s 258us/step - loss: 1.3346 - acc: 0.6680 - val_loss: 1.3945 - val_acc: 0.6790\n",
            "Epoch 4/20\n",
            "7982/7982 [==============================] - 2s 260us/step - loss: 1.1438 - acc: 0.7265 - val_loss: 1.3224 - val_acc: 0.6940\n",
            "Epoch 5/20\n",
            "7982/7982 [==============================] - 2s 258us/step - loss: 1.0121 - acc: 0.7453 - val_loss: 1.2708 - val_acc: 0.7030\n",
            "Epoch 6/20\n",
            "7982/7982 [==============================] - 2s 262us/step - loss: 0.9106 - acc: 0.7578 - val_loss: 1.2768 - val_acc: 0.7090\n",
            "Epoch 7/20\n",
            "7982/7982 [==============================] - 2s 259us/step - loss: 0.8308 - acc: 0.7735 - val_loss: 1.2572 - val_acc: 0.7110\n",
            "Epoch 8/20\n",
            "7982/7982 [==============================] - 2s 261us/step - loss: 0.7688 - acc: 0.7899 - val_loss: 1.2645 - val_acc: 0.7190\n",
            "Epoch 9/20\n",
            "7982/7982 [==============================] - 2s 263us/step - loss: 0.7123 - acc: 0.8016 - val_loss: 1.2927 - val_acc: 0.7080\n",
            "Epoch 10/20\n",
            "7982/7982 [==============================] - 2s 260us/step - loss: 0.6618 - acc: 0.8113 - val_loss: 1.3235 - val_acc: 0.7090\n",
            "Epoch 11/20\n",
            "7982/7982 [==============================] - 2s 260us/step - loss: 0.6177 - acc: 0.8200 - val_loss: 1.3498 - val_acc: 0.7150\n",
            "Epoch 12/20\n",
            "7982/7982 [==============================] - 2s 258us/step - loss: 0.5791 - acc: 0.8350 - val_loss: 1.3868 - val_acc: 0.7160\n",
            "Epoch 13/20\n",
            "7982/7982 [==============================] - 2s 259us/step - loss: 0.5412 - acc: 0.8448 - val_loss: 1.4431 - val_acc: 0.7090\n",
            "Epoch 14/20\n",
            "7982/7982 [==============================] - 2s 264us/step - loss: 0.5085 - acc: 0.8558 - val_loss: 1.4673 - val_acc: 0.7150\n",
            "Epoch 15/20\n",
            "7982/7982 [==============================] - 2s 257us/step - loss: 0.4793 - acc: 0.8678 - val_loss: 1.5205 - val_acc: 0.7180\n",
            "Epoch 16/20\n",
            "7982/7982 [==============================] - 2s 261us/step - loss: 0.4506 - acc: 0.8795 - val_loss: 1.5338 - val_acc: 0.7080\n",
            "Epoch 17/20\n",
            "7982/7982 [==============================] - 2s 268us/step - loss: 0.4267 - acc: 0.8824 - val_loss: 1.5728 - val_acc: 0.7210\n",
            "Epoch 18/20\n",
            "7982/7982 [==============================] - 2s 271us/step - loss: 0.4045 - acc: 0.8913 - val_loss: 1.6185 - val_acc: 0.7130\n",
            "Epoch 19/20\n",
            "7982/7982 [==============================] - 2s 274us/step - loss: 0.3852 - acc: 0.8940 - val_loss: 1.6491 - val_acc: 0.7190\n",
            "Epoch 20/20\n",
            "7982/7982 [==============================] - 2s 273us/step - loss: 0.3666 - acc: 0.8974 - val_loss: 1.7285 - val_acc: 0.7120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6980433ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "pkisKW63_sV5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "검증 정확도의 최고 값은 약 71%로 8% 정도 감소했다. 이런 손실의 대부분 원인은 많은 정보(46개 클래스의 분할 초평면을 복원하기에 충분한 정보)를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문이다. 이 네트워크는 필요한 정보 대부분을 4차원 표현 안에 구겨 넣었지만 전부는 넣지 못했다.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "S2yw-4Xw_sYp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "4월 28일 이후\n",
        "\n",
        "\n",
        "# 추가 실험\n",
        "더 크거나 작은 층을 사용해 보세요: 32개 유닛, 128개 유닛 등\n",
        "여기에서 두 개의 은닉층을 사용했습니다. 한 개의 은닉층이나 세 개의 은닉층을 사용해 보세요."
      ]
    },
    {
      "metadata": {
        "id": "C3HSrFsT_sbq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 정리\n",
        "\n",
        "* N개의 클래스로 데이터 포인트를 분류하려면 네트워크의 마지막 Dense 층의 크기는 N이어야 한다.\n",
        "* 단일 레이블, 다중 분류 문제에서는 N개의 클래스에 대한 확률 분포를 출력하기 위해 softmax 활성화 함수를 사용해야 한다.\n",
        "* 이런 문제에는 항상 범주형 크로스엔트로피를 사용해야 한다. 이 함수는 모델이 출력한 확률 분포와 타깃 분포 사이의 거리를 최소화한다.\n",
        "* 다중 분류에서 레이블을 다루는 두 가지 방법이 있다.\n",
        ">* 레이블을 범주형 인코딩(또는 원-핫 인코딩)으로 인코딩하고 categorical_crossentropy 손실 함수를 사용한다.\n",
        ">* 레이블을 정수로 인코딩하고 sparse_categorical_crossentropy 손실 함수를 사용한다.\n",
        "* 많은 수의 범주를 분류할 때 중간층의 크기가 너무 작아 네트워크에 정보의 병목이 생기지 않도록 해야 한다."
      ]
    }
  ]
}