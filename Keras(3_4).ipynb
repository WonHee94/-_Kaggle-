{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras(3.4).ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "68O602vPoFL8",
        "colab_type": "code",
        "outputId": "4656c779-9f31-4d5f-930e-f3bc4e797294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "# 케라스 창시자에게 배우는 딥러닝 공부\n",
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "eFHck8LsqL3P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **3.2 영화 리뷰 분류 : 이진 분류 예제**\n",
        "\n",
        "리뷰 택스트를 기반으로 영화 리뷰를 긍정과 부정으로 분류하는 방법 익히기\n",
        "\n",
        ">5만개의  IMDB 데이터셋이용\n",
        "\n",
        ">케라스에 포함된 데이터로 전처리되어 있어 각 리부(단어시퀀스)가 숫자 시퀀스로 변환되어 있다. 숫자는 사전에 있는 고유한 단어를 나타냄\n",
        "\n",
        ">train :2만5천개, test : 2만5천개 (각각 50대50으로 긍정부정 리뷰 구성)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RtyQHJy9qEyL",
        "colab_type": "code",
        "outputId": "8a0d7300-8134-44ac-fd91-cd425dddb150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tH6nHFopsCWv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "train data에서 가장 자주 나타나는 단어 만개만 사용하기 위하기 위해 매개변수 num_words=10000으로 지정\n",
        "드물게 나타나는 단어는 무시할 것이다.\n",
        "이유 : 적절한 크기의 벡터 데이터를 얻을 수 있기때문에\n"
      ]
    },
    {
      "metadata": {
        "id": "acZf1v06qE6v",
        "colab_type": "code",
        "outputId": "73526191-b2c4-4f4d-9125-f86db22f4f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3941
        }
      },
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "6oeGDCKdqE9f",
        "colab_type": "code",
        "outputId": "4f119174-947f-45cc-9f90-b82fdcbd5cfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_labels[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "2B52Yx8Ms9u7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "num_words=10000로 제한했기 떄문에 단어의 index는 만을 넘지 않는다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "keT9uYJEtfQj",
        "colab_type": "code",
        "outputId": "1c628399-b11d-4193-82cf-7f002a398c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "max([max(sequence) for sequence in train_data])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "U89KMJrSthVL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "리뷰 데이터 하나를 원래 영어 단어로 바꾸기"
      ]
    },
    {
      "metadata": {
        "id": "qHVUc7lAqE__",
        "colab_type": "code",
        "outputId": "6c4c9ca5-cdf4-4a7b-bf7a-1096b5714abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "# word_index는 단어와 정수 인덱스를 매핑한 딕셔너리입니다\n",
        "word_index = imdb.get_word_index()\n",
        "# 정수 인덱스와 단어를 매핑하도록 뒤집습니다\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "# 리뷰를 디코딩합니다. \n",
        "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R-NfZqE8qFCw",
        "colab_type": "code",
        "outputId": "f8830140-7cb4-48a6-f8ec-5e69dfaa240e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "decoded_review"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "GTbwUHLbuDsP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 데이터 준비\n",
        "\n",
        "신경망에 숫자 리스트를 넣을 수 없다. 리스트를 텐서로 바꾸는 작업이 필요\n",
        "\n",
        ">방법1 : 같은 길이가 되도록 리스트에 패딩을 추가하고 (samples, sequence_length) 크기의 정수 텐서로 변환하기.  이 정수 텐서를 다룰 수 있는 층을 신경망의 첫 번째 층으로 사용한다. (Embedding 층을 말하며 나중에 자세히 다룸).\n",
        "\n",
        ">방법2 : 리스트를 원-핫 인코딩하여 0과1의 벡터로 변환하기. (ex. 시퀀스[3,5]를 index 3과 5의 위치는 1이고 그외는 모두 0인 10,000벡터로 각각 변환한다.) 이후 부동 소수 벡터 데이터를 다룰 수 있는 Dense층을 신경망의 첫 번쨰 층으로 사용\n",
        "\n",
        ">방법 2를 이용해 보기\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "부동소수란?\n",
        "\n",
        "부동소수점(浮動小數點, floating point) 또는 떠돌이 소수점[1] 방식은 ***실수를 컴퓨터 상에서 근사하여 표현할 때 소수점의 위치를 고정하지 않고 그 위치를 나타내는 수를 따로 적는 것***으로, 유효숫자를 나타내는 가수(假數)와 소수점의 위치를 풀이하는 지수(指數)로 나누어 표현한다.\n",
        "\n",
        "컴퓨터에서는 고정 소수점 방식보다 넓은 범위의 수를 나타낼 수 있어 과학기술 계산에 많이 이용되지만, 근삿값으로 표현되며[2] 고정 소수점 방식보다 연산 속도가 느리기 때문에 별도의 전용 연산 장치를 두는 경우가 많다. 고정 소수점과 달리 정수 부분과 소수 부분의 자릿수가 일정하지 않으나, 유효 숫자의 자릿수는 정해져 있다.[출처 : 위키백과]\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Wuep2WC5qFE_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#리스트를 원-핫 인코딩하여 0과1의 벡터로 변환하기\n",
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
        "    return results\n",
        "\n",
        "# 훈련 데이터를 벡터로 변환합니다\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# 테스트 데이터를 벡터로 변환합니다\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F-D4vTyOqFHf",
        "colab_type": "code",
        "outputId": "04dc7918-a5cd-4858-bb90-9aeb81d94521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "q4sC4DmFqFMf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 레이블을 벡터로 바꿉니다\n",
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Llrfd-Vwytz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 신경망 모델 만들기\n",
        "입력 데이터는 벡터이고 레이블은 스칼라(1 또는 0).  이런 문제에 잘 작동하는 네트워크 종류는 relu 활성화 함수를 사용한 완전 연결 층(즉, Dense(16, activation='relu'))을 그냥 쌓은 것이다.\n",
        "\n",
        "Dense 층에 전달한 매개변수(16)는 은닉 유닛의 개수다. 하나의 은닉 유닛은 층이 나타내는 표현 공간에서 하나의 차원이 된다. \n",
        "\n",
        "2장에서 relu 활성화 함수를 사용한 Dense 층을 다음과 같은 텐서 연산을 연결하여 구현함:\n",
        "output = relu(dot(W, input) + b)\n",
        "\n",
        "16개의 은닉 유닛이 있다는 것은 가중치 행렬 W의 크기가 (input_dimension, 16)이라는 뜻이다. 입력 데이터와 W를 점곱하면 입력 데이터가 16 차원으로 표현된 공간으로 투영된다(그리고 편향 벡터 b를 더하고 relu 연산을 적용). 표현 *공간의 차원을 '신경망이 내재된 표현을 학습할 때 가질 수 있는 자유도'로 이해*할 수 있다. 은닉 유닛을 늘리면 (표현 공간을 더 고차원으로 만들면) 신경망이 더욱 복잡한 표현을 학습할 수 있지만 계산 비용이 커지고 원치 않은 패턴을 학습할 수도 있다(훈련 데이터에서는 성능이 향상되지만 테스트 데이터에서는 그렇지 않은 패턴을 보임).\n",
        "\n",
        "Dense 층을 쌓을 때 두 가진 중요한 구조상의 결정이 필요:\n",
        "\n",
        ">1. 얼마나 많은 층을 사용할 것인가?\n",
        "\n",
        ">2. 각 층에 얼마나 많은 은닉 유닛을 둘 것인가?\n",
        "\n",
        "4장에서 이런 결정을 하는 데 도움이 되는 일반적인 원리를 배움.\n",
        "\n",
        "16개의 은닉 유닛을 가진 두 개의 은닉층\n",
        "현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 세 번째 층\n",
        "중간에 있는 은닉층은 활성화 함수로 relu를 사용하고 마지막 층은 확률(0과 1 사이의 점수로, 어떤 샘플이 타깃 '1'일 가능성이 높다는 것은 그 리뷰가 긍정일 가능성이 높다는 것을 의미)을 출력하기 위해 시그모이드 활성화 함수를 사용한다. relu는 음수를 0으로 만드는 함수*. 시그모이드는 임의의 값을 [0, 1] 사이로 압축하므로 출력 값을 확률처럼 해석할 수 있다.*\n",
        "\n",
        "신경망 모습:\n",
        "![대체 텍스트](https://camo.githubusercontent.com/ad8a581c483ced840d4a471329d8654e41883d79/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f626f6f6b2e6b657261732e696f2f696d672f6368332f335f6c617965725f6e6574776f726b2e706e67)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "이 신경망의 케라스 구현:\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "o1RsRnRrqFPQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d1xldmIyzF-y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "마지막으로 손실 함수와 옵티마이저를 선택해야 한다. 이진 분류 문제이고 신경망의 출력이 확률이기 때문에(네트워크의 끝에 시그모이드 활성화 함수를 사용한 하나의 유닛으로 된 층을 놓았다), binary_crossentropy 손실이 적합하다. 이 함수가 유일한 선택은 아니다. mean_squared_error를 사용할 수도 있다.\n",
        "\n",
        "확률을 출력하는 모델을 사용할 때는 크로스엔트로피가 최선의 선택이다. 크로스엔트로피는 정보 이론 분야에서 온 개념으로 확률 분포 간의 차이를 측정한다. 여기에서는 원본 분포와 예측 분포 사이를 측정한다.\n",
        "\n",
        "다음은 rmsprop 옵티마이저와 binary_crossentropy 손실 함수로 모델을 설정하는 단계이다. 훈련하는 동안 정확도를 사용해 모니터링하자."
      ]
    },
    {
      "metadata": {
        "id": "iG4XgA5OqFR_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l9idwh1Jztdb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "케라스에 rmsprop, binary_crossentropy, accuracy가 포함되어 있기 때문에 옵티마이저, 손실 함수, 측정 지표를 문자열로 지정하는 것이 가능하다. 이따금 옵티마이저의 매개변수를 바꾸거나 자신만의 손실 함수, 측정 함수를 전달해야 할 경우가 있는데 전자의 경우에는 옵티마이저 파이썬 클래스를 사용해 객체를 직접 만들어 optimizer 매개변수에 전달하면 된다. 후자의 경우는 loss와 metrics 매개변수에 함수 객체를 전달한다."
      ]
    },
    {
      "metadata": {
        "id": "fWkIqVjZqF0T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#옵티마이저 파이썬 클래스를 사용해 객체를 직접 만들어 optimizer 매개변수에 전달\n",
        "\n",
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0EtbLxPYqF3D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#loss와 metrics 매개변수에 함수 객체를 전달"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "La-0iMNnqF5j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import losses\n",
        "from keras import metrics\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss=losses.binary_crossentropy,\n",
        "              metrics=[metrics.binary_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hHx-VcfEqF8T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eoJa1Gby0sAC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 훈련 검증\n",
        "훈련하는 동안 처음 본 데이터에 대한 모델의 정확도를 측정하기 위해서는 원본 훈련 데이터에서 10,000의 샘플을 떼어서 검증 세트를 만들자"
      ]
    },
    {
      "metadata": {
        "id": "STDV1S_UqF-z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n8g_wzWi01FW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이제 모델을 512개 샘플씩 미니 배치를 만들어 20번의 에포크 동안 훈련시키자(x_train과 y_train 텐서에 있는 모든 샘플에 대해 20번 반복). 동시에 따로 떼어 놓은 10,000개의 샘플에서 손실과 정확도를 측정할 것이다. 이렇게 하려면 validation_data 매개변수에 검증 데이터를 전달해야 한다."
      ]
    },
    {
      "metadata": {
        "id": "F023x9VZ00KO",
        "colab_type": "code",
        "outputId": "802c7b7d-e0c7-41fa-fd94-0bc1297eab01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 4s 234us/step - loss: 0.5363 - acc: 0.7760 - val_loss: 0.4001 - val_acc: 0.8675\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 3s 195us/step - loss: 0.3203 - acc: 0.8986 - val_loss: 0.3268 - val_acc: 0.8736\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 3s 190us/step - loss: 0.2342 - acc: 0.9249 - val_loss: 0.2856 - val_acc: 0.8867\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 3s 190us/step - loss: 0.1837 - acc: 0.9403 - val_loss: 0.2737 - val_acc: 0.8908\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 3s 191us/step - loss: 0.1517 - acc: 0.9511 - val_loss: 0.2997 - val_acc: 0.8814\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 3s 191us/step - loss: 0.1227 - acc: 0.9623 - val_loss: 0.2877 - val_acc: 0.8869\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 3s 191us/step - loss: 0.1064 - acc: 0.9669 - val_loss: 0.3042 - val_acc: 0.8835\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 3s 191us/step - loss: 0.0862 - acc: 0.9751 - val_loss: 0.3221 - val_acc: 0.8811\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 3s 190us/step - loss: 0.0697 - acc: 0.9824 - val_loss: 0.3406 - val_acc: 0.8802\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 3s 189us/step - loss: 0.0602 - acc: 0.9843 - val_loss: 0.3854 - val_acc: 0.8764\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 3s 192us/step - loss: 0.0473 - acc: 0.9895 - val_loss: 0.3964 - val_acc: 0.8737\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 3s 194us/step - loss: 0.0391 - acc: 0.9920 - val_loss: 0.4219 - val_acc: 0.8725\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 3s 195us/step - loss: 0.0341 - acc: 0.9933 - val_loss: 0.4558 - val_acc: 0.8744\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 3s 196us/step - loss: 0.0255 - acc: 0.9950 - val_loss: 0.4899 - val_acc: 0.8717\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 3s 196us/step - loss: 0.0188 - acc: 0.9968 - val_loss: 0.5320 - val_acc: 0.8634\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 3s 194us/step - loss: 0.0166 - acc: 0.9975 - val_loss: 0.5412 - val_acc: 0.8679\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 3s 194us/step - loss: 0.0129 - acc: 0.9983 - val_loss: 0.5746 - val_acc: 0.8673\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 3s 194us/step - loss: 0.0107 - acc: 0.9985 - val_loss: 0.6048 - val_acc: 0.8647\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 3s 192us/step - loss: 0.0063 - acc: 0.9997 - val_loss: 0.6624 - val_acc: 0.8652\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 3s 190us/step - loss: 0.0080 - acc: 0.9988 - val_loss: 0.6639 - val_acc: 0.8649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KD_gU10C1EVt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "model.fit() 메서드는 History 객체를 반환한다. 이 객체는 훈련하는 동안 발생한 모든 정보를 담고 있는 딕셔너리인 history 속성을 가지고 있다. "
      ]
    },
    {
      "metadata": {
        "id": "XCueEUgd1PuX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QX_9Nm4u1RRH",
        "colab_type": "code",
        "outputId": "f5f4ce04-330e-45ac-f887-05e6c24ab712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# ‘bo’는 파란색 점을 의미합니다\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# ‘b’는 파란색 실선을 의미합니다\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nivx/S8SBf6ARS1kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Bju8lIN-1XMD",
        "colab_type": "code",
        "outputId": "6cab14c1-3a3f-4973-968e-0e44fb72e645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "plt.clf()   # 그래프를 초기화합니다\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "#acc = history_dict['acc']\n",
        "#val_acc = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKdaLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "yqXDR60S2gaq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "점선은 훈련 손실과 정확도이고 실선은 검증 손실과 정확도이다. 신경망의 무작위한 초기화 때문에 사람마다 결과거 조금 다름.\n",
        "\n",
        "훈련 손실이 에포크마다 감소하고 훈련 정확도는 에포크마다 증가한다. 경사 하강법 최적화를 사용했을 때 반복마다 최소화되는 것이 손실이므로 기대와 같다. 검증 손실과 정확도는 이와 같지 않다. 4번째 에포크에서 그래프가 역전데 이것이 훈련 세트에서 잘 작동하는 모델이 처음 보는 데이터에 잘 작동하지 않을 수 있다고 앞서 언급한 경고의 한 사례다. 정확한 용어로 말하면 과대적합. 2번째 에포크 이후부터 훈련 데이터에 과도하게 최적화되어 훈련 데이터에 특화된 표현을 학습하므로 훈련 세트 이외의 데이터에는 일반화되지 못한다.\n",
        "\n",
        "이런 경우에 과대적합을 방지하기 위해서 3번째 에포크 이후에 훈련을 중지한다. \n",
        "\n",
        "처음부터 다시 새로운 신경망을 4번의 에포크 동안만 훈련하고 테스트 데이터에서 평가해 보자:"
      ]
    },
    {
      "metadata": {
        "id": "Z3KGwuFB3Kh6",
        "colab_type": "code",
        "outputId": "68feb15d-e8e8-4b09-b548-15050bb2901d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "25000/25000 [==============================] - 4s 150us/step - loss: 0.4738 - acc: 0.8217\n",
            "Epoch 2/4\n",
            "25000/25000 [==============================] - 3s 139us/step - loss: 0.2673 - acc: 0.9093\n",
            "Epoch 3/4\n",
            "25000/25000 [==============================] - 3s 137us/step - loss: 0.2032 - acc: 0.9286\n",
            "Epoch 4/4\n",
            "25000/25000 [==============================] - 3s 136us/step - loss: 0.1711 - acc: 0.9387\n",
            "25000/25000 [==============================] - 2s 77us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-yUCreHc3Q0y",
        "colab_type": "code",
        "outputId": "ec7742e5-444c-4b6f-a2cb-3e4ae0fa4437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3124895779132843, 0.87584]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "AzjjtF073cJm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " 87%의 정확도를 달성. 최고 수준의 기법을 사용하면 95%에 가까운 성능을 얻을 수 있다."
      ]
    },
    {
      "metadata": {
        "id": "brc9KZdL3Yca",
        "colab_type": "code",
        "outputId": "9ee69e9a-bbc5-4b4f-804a-a854d10f75f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16219068],\n",
              "       [0.99984837],\n",
              "       [0.39698157],\n",
              "       ...,\n",
              "       [0.08048674],\n",
              "       [0.04885855],\n",
              "       [0.45590666]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "I8X2GpHQ3R2f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 모델은 어떤 샘플에 대해 확신을 가지고 있지만(0.99 또는 그 이상, 0.01 또는 그 이하) 어떤 샘플에 대해서는 확신이 부족하다(0.6, 0.4).\n"
      ]
    },
    {
      "metadata": {
        "id": "jBowQUlW30OH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "--------\n",
        "4월 28일 이후 진행예정\n",
        "\n",
        "\n",
        "# 추가 실험\n",
        "여기에서는 두 개의 은닉층을 사용했습니다. 한 개 또는 세 개의 은닉층을 사용하고 검증과 테스트 정확도에 어떤 영향을 미치는지 확인해 보세요.\n",
        "층의 은닉 유닛을 추가하거나 줄여 보세요: 32개 유닛, 64개 유닛 등\n",
        "binary_crossentropy 대신에 mse 손실 함수를 사용해 보세요.\n",
        "relu 대신에 tanh 활성화 함수(초창기 신경망에서 인기 있었던 함수입니다)를 사용해 보세요.\n",
        "다음 실험을 진행하면 여기에서 선택한 구조가 향상의 여지는 있지만 어느 정도 납득할 만한 수준이라는 것을 알게 것입니다!"
      ]
    },
    {
      "metadata": {
        "id": "IEYLaOw94CYP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 정리\n",
        "\n",
        "* 원본 데이터를 신경망에 텐서로 주입하기 위해서는 꽤 많은 전처리가 필요하다. 단어 시퀀스는 이진 벡터로 인코딩될 수 있고 다른 인코딩 방식도 있다.\n",
        "* relu 활성화 함수와 함께 Dense 층을 쌓은 네트워크는 (감성 분류를 포함하여) 여러 종류의 문제에 적용할 수 있어서 앞으로 자주 사용하게 된다.\n",
        "* (출력 클래스가 두 개인) 이진 분류 문제에서 네트워크는 하나의 유닛과 sigmoid 활성화 함수를 가진 Dense 층으로 끝나야 한다. 이 신경망의 출력은 확률을 나타내는 0과 1 사이의 스칼라 값이다.\n",
        "* 이진 분류 문제에서 이런 스칼라 시그모이드 출력에 대해 사용할 손실 함수는 binary_crossentropy이다.\n",
        "* rmsprop 옵티마이저는 문제에 상관없이 일반적으로 충분히 좋은 선택이다.\n",
        "* 훈련 데이터에 대해 성능이 향상됨에 따라 신경망은 과대적합되기 시작하고 이전에 본적 없는 데이터에서는 결과가 점점 나빠지게 된다. 항상 훈련 세트 이외의 데이터에서 성능을 모니터링해야 한다."
      ]
    }
  ]
}